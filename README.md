# Neural Deck

A sleek Electron desktop client for [Ollama](https://ollama.com) and [LM Studio](https://lmstudio.ai) with a Linux terminal‚Äìinspired UI.

![Electron](https://img.shields.io/badge/Electron-34-47848F?logo=electron&logoColor=white)
![Node](https://img.shields.io/badge/Node-18+-339933?logo=node.js&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

<p>
  <img src="screenshot1.png" alt="Neural Deck" width="600" />
  <img src="screenshot2.png" alt="Neural Deck Chat" width="600" />
  <img src="screenshot3.png" alt="Neural Deck Settings" width="600" />
  <img src="screenshot4.png" alt="Neural Deck Hack Sim" width="600" />
  <img src="screenshot5.png" alt="Neural Deck Hack Output" width="600" />
</p>

## Features

- **Streaming chat** ‚Äî real-time token streaming with stop/cancel support
- **Multi-provider** ‚Äî switch between Ollama and LM Studio from the Provider dropdown; URL auto-switches to default ports
- **AI tool calling** ‚Äî Gemini-style tool use; the model can query weather, time, IP info, and web search using free APIs ‚Äî no API keys needed
- **Model capability icons** ‚Äî üëÅ vision, üîß tool-calling ‚Äî icons in the model dropdown so you know what each model supports
- **Vision model support** ‚Äî attach images and use vision-capable models for image analysis
- **Image & file attachments** ‚Äî attach images (base64 for vision models) or text files to your prompts; attached files display as chips in the chat history
- **Emoji picker** ‚Äî built-in emoji panel with 8 categorized tabs and search
- **Hack simulation** ‚Äî built-in slash commands that play animated terminal-style hacking sequences
- **System prompt modes** ‚Äî Default (Sojourner persona), None, or Custom with your own prompt
- **Smart Port Switching** ‚Äî automatically swaps ports (11434 ‚Üî 1234) when switching providers while preserving your custom hostname
- **System Restore** ‚Äî "Reset Protocols" button to wipe settings and restore factory defaults
- **Persistent chat history** ‚Äî choose between in-memory or disk-based history storage
- **Encrypted history** ‚Äî optional AES-256-GCM encryption for disk-stored conversations
- **Performance stats** ‚Äî tokens/sec and token count displayed on every response
- **Configurable parameters** ‚Äî temperature, max tokens, context length, chunk size
- **Agent naming** ‚Äî customize the assistant's display name (default: Sojourner)
- **Auto-persistence** ‚Äî all settings saved automatically to a local config file
- **Neural Interface** ‚Äî cyberpunk/terminal aesthetic with glassmorphism, scanlines, and animated "hack" style loaders

## Prerequisites

- [Node.js](https://nodejs.org) 18+
- [Ollama](https://ollama.com) and/or [LM Studio](https://lmstudio.ai) running locally (or on a reachable server)

## Quick Start

```bash
# Clone / copy the project
git clone <git@github.com:MuchDevSuchCode/NeuralLink.git> neural-deck
cd neural-deck

# Install dependencies
npm install

# Launch
npm start
```

The app will auto-connect to `http://localhost:11434` and fetch available models on startup.

## Usage

1. **Provider** ‚Äî select Ollama or LM Studio from the Provider dropdown
2. **Connect** ‚Äî enter your server URL in the top bar and click the refresh button (auto-fills default port)
3. **Select a model** ‚Äî pick from the dropdown (üëÅ = vision, üîß = tool-calling)
4. **Chat** ‚Äî type a message and press Enter or click Send
5. **Ask real-world questions** ‚Äî models with üîß can fetch live weather, time, IP info, and web search results
6. **Attach files** ‚Äî use the üì∑ (image) or üìé (file) buttons next to the input
7. **Emoji** ‚Äî click the üòä smiley button to open the emoji picker; click any emoji to insert it at your cursor
8. **Hack sim** ‚Äî type a `/` command to run a simulated hacking sequence (see below)
9. **Tune parameters** ‚Äî open the settings sidebar with the gear icon
10. **System Restore** ‚Äî use the "Reset Protocols" button at the bottom of settings to factory reset the app

### Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `Enter` | Send message |
| `Shift+Enter` | New line in input |
| `Escape` | Close emoji picker / encryption key modal |

## AI Tool Calling

Models with the üîß icon support **Ollama's native tool-calling API**. When you ask a real-world question, the model decides on its own whether to call a tool ‚Äî just like Gemini or ChatGPT.

### Available Tools

| Tool | API Source | Description |
|------|-----------|-------------|
| `get_weather` | [Open-Meteo](https://open-meteo.com) | Current conditions + 3-day forecast for any city |
| `get_time` | [WorldTimeAPI](https://worldtimeapi.org) | Current local time in any city/timezone |
| `get_ip_info` | [ip-api.com](http://ip-api.com) | IP geolocation lookup (defaults to your IP) |
| `web_search` | [DuckDuckGo](https://duckduckgo.com) | Quick factual web lookup |

All APIs are **free and require no API keys**.

### How It Works

1. You ask a question like *"What's the weather in Dallas?"*
2. The model returns a `tool_calls` request for `get_weather`
3. A pulsing `üîß Calling get_weather‚Ä¶` indicator appears
4. Neural Deck fetches real data from the API
5. The result goes back to the model, which writes a natural-language response
6. The response meta line shows `üîß 1 tool call(s)` when tools were used

> **Note:** Models without tool support (no üîß icon) work normally ‚Äî tool definitions are only sent to capable models. Tool support is auto-detected via Ollama's `/api/show` endpoint.

## Hack Simulation

Type slash commands in the chat input to trigger animated, Shadowrun-themed hacking sequences. These bypass the LLM entirely ‚Äî no model selection required.

| Command | Description |
|---------|-------------|
| `/hack <target>` | Multi-phase corporate host breach ‚Äî recon, ICE bypass, data extraction, cleanup |
| `/scan [target]` | Network reconnaissance ‚Äî port scanning, service enumeration, host fingerprinting |
| `/trace <ip>` | Trace a Matrix datatrail hop-by-hop to a physical location |
| `/decrypt <file>` | Cryptanalysis and brute-force decryption of an encrypted payload |
| `/nuke <target>` | Data bombardment attack ‚Äî multi-wave assault, ICE collapse, host destruction |
| `/help` | List all available commands |

All arguments are optional ‚Äî random Shadowrun-themed targets are generated when omitted. Every run is randomized with different megacorps, ICE types, ports, files, and locations.

**Animation features:**
- Character-by-character typing effects
- Animated progress bars (`[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 42%`)
- Scrolling hex dumps
- Spinning braille-character indicators
- Color-coded status lines (`[OK]` / `[WARN]` / `[FAIL]`)
- Blinking alert text for critical events

## System Prompt

The system prompt mode is selectable from the Settings sidebar:

| Mode | Behavior |
|------|----------|
| **Default** | Uses the built-in Sojourner persona ‚Äî a sovereign Digital Intelligence from the Sixth World |
| **None** | No system prompt is sent; the model runs with its base behavior |
| **Custom** | Reveals a textarea where you can write your own system prompt |

## Chat History

Neural Deck supports two history storage modes, configurable in the Settings sidebar under **History**:

### Memory (default)

Chat history lives only in the current session. Closing the app loses all conversation data.

### Disk

Chat history is written to `chat_history/current.json` in the app directory after every message. On restart, your conversation is automatically restored.

### Encrypted Disk

When the **Encrypt History** toggle is enabled (only visible in Disk mode), chat history is encrypted with **AES-256-GCM** before being saved to `chat_history/current.enc`.

- **Key derivation** ‚Äî your passphrase is run through `scryptSync` with a random 16-byte salt to derive a 256-bit key
- **Encryption** ‚Äî each save generates a fresh 12-byte IV; the file format is `salt(16) + iv(12) + authTag(16) + ciphertext`
- **Key prompt** ‚Äî a modal overlay prompts for your passphrase when encryption is first used and again on each app restart. The passphrase is held only in memory and never written to disk
- **Wrong passphrase** ‚Äî GCM's authentication tag detects incorrect keys and shows an error toast

> **Note:** The `chat_history/` directory is listed in `.gitignore` to prevent accidental commits of conversation data.

## Project Structure

```
neural-deck/
‚îú‚îÄ‚îÄ main.js            # Electron main process (window, IPC, file dialogs, crypto, web APIs)
‚îú‚îÄ‚îÄ preload.js         # Bridge between main & renderer (Ollama API, tool detection, history IPC)
‚îú‚îÄ‚îÄ renderer.js        # Frontend logic (chat, tool calling, markdown, attachments, emoji, history)
‚îú‚îÄ‚îÄ hack-commands.js   # Simulated hacking command engine & animations
‚îú‚îÄ‚îÄ index.html         # App layout & structure
‚îú‚îÄ‚îÄ styles.css         # Terminal-themed styling
‚îú‚îÄ‚îÄ ndlogo.png         # App logo (welcome screen)
‚îú‚îÄ‚îÄ ndicon.png         # App icon (top bar)
‚îú‚îÄ‚îÄ .gitignore         # Excludes node_modules/ and chat_history/
‚îú‚îÄ‚îÄ chat_history/      # Auto-created; stores persisted conversations
‚îî‚îÄ‚îÄ package.json
```

## Configuration

Settings are auto-saved to `<userData>/config.json` and restored on launch:

| Setting | Default | Description |
|---------|---------|-------------|
| Provider | `ollama` | Backend provider (`ollama` or `lmstudio`) |
| Server URL | `http://localhost:11434` | API endpoint (auto-switches port on provider change) |
| Temperature | `0.7` | Sampling temperature (0 = precise, 2 = creative) |
| Max Tokens | `2048` | Maximum tokens to generate |
| Context Length | `4096` | Context window size (`num_ctx`) |
| Chunk Size | `512` | Prompt batch size (`num_batch`) |
| Stream | `true` | Stream tokens in real-time |
| Agent Name | `Sojourner` | Display name for the AI |
| Prompt Mode | `default` | `default`, `none`, or `custom` |
| System Prompt | *(empty)* | Custom system message (used when Prompt Mode is `custom`) |
| History Mode | `memory` | `memory` or `disk` |
| Encrypt History | `false` | Enable AES-256-GCM encryption for disk history |

## API

The client supports two backend providers:

### Ollama

- `GET /api/tags` ‚Äî list models (with vision detection via `details.families`)
- `POST /api/show` ‚Äî detect tool-calling support (checks model template for tool tokens)
- `POST /api/chat` ‚Äî chat completion (streaming via NDJSON, with optional tool calling)

Default: `http://localhost:11434`

### LM Studio

- `GET /v1/models` ‚Äî list loaded models (OpenAI-compatible)
- `POST /v1/chat/completions` ‚Äî chat completion (streaming via SSE, OpenAI format)

Default: `http://localhost:1234`

Both providers also support these free external APIs for tool-call results:

- [Open-Meteo](https://open-meteo.com) ‚Äî weather and geocoding
- [WorldTimeAPI](https://worldtimeapi.org) ‚Äî timezone and current time
- [ip-api.com](http://ip-api.com) ‚Äî IP geolocation
- [DuckDuckGo Instant Answer](https://api.duckduckgo.com) ‚Äî web search

## Security

- Encryption uses **AES-256-GCM** ‚Äî an authenticated encryption scheme that provides both confidentiality and integrity
- Key derivation uses **scrypt** (`N=16384, r=8, p=1`) with a unique random salt per save
- The passphrase is **never persisted** ‚Äî it's held only in a JavaScript variable for the duration of the session
- The encryption key modal is **separate from the chat** ‚Äî passphrase input is never added to chat history or sent to the model
- Web tool API calls are made from the **main process** ‚Äî no direct network access from the renderer

## License

MIT
